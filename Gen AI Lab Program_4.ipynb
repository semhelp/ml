{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb333be-6918-42d9-9c3a-1ec694175a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute in collab only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06a7a7-1513-498c-a5b1-26fda708cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gensim for downloading pre-trained models\n",
    "!pip install numpy\n",
    "!pip install gensim\n",
    "!pip install \"numba>=0.53,<1.23\"  # Adjust version if needed\n",
    "!pip install \"tensorflow>=2.1,<2.19\" # Adjust version if needed\n",
    "# Install Hugging Face Transformers for NLP pipelines\n",
    "!pip install transformers\n",
    "\n",
    "# Install NLTK for text preprocessing and tokenization\n",
    "!pip install nltk\n",
    "\n",
    "# [2] - Import libraries\n",
    "import torch\n",
    "import gensim.downloader\n",
    "api = gensim.downloader\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the 'punkt' resource from NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "print(\"Loading pre-trained word vectors...\")\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # Load Word2Vec model\n",
    "\n",
    "# [6] - Function to replace words in the prompt with their most similar words\n",
    "def replace_keyword_in_prompt(prompt, keyword, word_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    Replace only the specified keyword in the prompt with its most similar word.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The original input prompt.\n",
    "        keyword (str): The word to be replaced with a similar word.\n",
    "        word_vectors (gensim.models.KeyedVectors): Pre-trained word embeddings.\n",
    "        topn (int): Number of top similar words to consider (default: 1).\n",
    "\n",
    "    Returns:\n",
    "        str: The enriched prompt with the keyword replaced.\n",
    "    \"\"\"\n",
    "    words = word_tokenize(prompt)  # Tokenize the prompt into words\n",
    "    enriched_words = []\n",
    "\n",
    "    for word in words:\n",
    "        cleaned_word = word.lower().strip(string.punctuation)  # Normalize word\n",
    "        if cleaned_word == keyword.lower():  # Replace only if it matches the keyword\n",
    "            try:\n",
    "                # Retrieve similar word\n",
    "                similar_words = word_vectors.most_similar(cleaned_word, topn=topn)\n",
    "                if similar_words:\n",
    "                    replacement_word = similar_words[0][0]  # Choose the most similar word\n",
    "                    print(f\"Replacing '{word}' â†’ '{replacement_word}'\")\n",
    "                    enriched_words.append(replacement_word)\n",
    "                else:\n",
    "                    enriched_words.append(word)\n",
    "            except KeyError:\n",
    "                print(f\"'{keyword}' not found in the vocabulary. Using original word.\")\n",
    "                enriched_words.append(word)\n",
    "        else:\n",
    "            enriched_words.append(word)  # Keep original if no replacement was made\n",
    "\n",
    "    enriched_prompt = ' '.join(enriched_words)\n",
    "    print(f\"\\nEnriched Prompt: {enriched_prompt}\")\n",
    "    return enriched_prompt\n",
    "\n",
    "# [7] - Install torch and related libraries\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "# [8] - Load an open-source Generative AI model (GPT-2)\n",
    "print(\"\\nLoading GPT-2 model...\")\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", framework=\"pt\")\n",
    "\n",
    "# [9] - Function to generate responses using the Generative AI model\n",
    "def generate_response(prompt, max_length=100):\n",
    "    try:\n",
    "        response = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
    "        return response[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None\n",
    "\n",
    "# [10] - Example original prompt\n",
    "original_prompt = \"Who is king.\"\n",
    "print(\"\\n Original Prompt: {original_prompt}\")\n",
    "\n",
    "# [11] - Retrieve similar words for key terms in the prompt\n",
    "key_term = \"king\"\n",
    "\n",
    "enriched_prompt = replace_keyword_in_prompt(original_prompt, key_term, word_vectors)\n",
    "\n",
    "# [13] - Generate responses for the original and enriched prompts\n",
    "print(\"\\nGenerating response for the original prompt...\")\n",
    "original_response = generate_response(original_prompt)\n",
    "print(\"Original Prompt Response:\")\n",
    "print(original_response)\n",
    "\n",
    "print(\"\\nGenerating response for the enriched prompt...\")\n",
    "enriched_response = generate_response(enriched_prompt)\n",
    "print(\"Enriched Prompt Response:\")\n",
    "print(enriched_response)\n",
    "\n",
    "# [14] - Compare the outputs of responses\n",
    "print(\"\\nComparison of Responses:\")\n",
    "print(\"Original Prompt Response Length:\", len(original_response))\n",
    "print(\"Enriched Prompt Response Length:\", len(enriched_response))\n",
    "print(\"Original Prompt Response Details:\", original_response.count('.'))\n",
    "print(\"Enriched Prompt Response Details:\", enriched_response.count('.'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
